{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Wizard Assistant: Model Implementation\n",
    "\n",
    "This notebook demonstrates the implementation of the RAG model for the Email Wizard Assistant. We'll embed the preprocessed emails, set up the retrieval system, and implement the response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "# Import project modules\n",
    "from src.data.dataset import load_dataset\n",
    "from src.model.embeddings import EmailEmbedder, ChromaDBStore\n",
    "from src.model.retriever import EmailRetriever, ChromaDBRetriever\n",
    "from src.model.generator import ResponseGenerator, RAGPipeline\n",
    "from src.utils.helpers import time_function, save_json, load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Emails\n",
    "\n",
    "First, let's load the preprocessed emails from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load preprocessed emails\n",
    "processed_emails = load_dataset(\n",
    "    \"../data/processed/processed_emails.json\",\n",
    "    is_processed=True\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(processed_emails)} preprocessed emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embed Emails\n",
    "\n",
    "Now, let's embed the preprocessed emails using a pre-trained Sentence Transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the embedder\n",
    "embedder = EmailEmbedder(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed the emails\n",
    "@time_function\n",
    "def embed_emails(emails):\n",
    "    return embedder.embed_emails(emails)\n",
    "\n",
    "emails_with_embeddings = embed_emails(processed_emails)\n",
    "\n",
    "# Save the embeddings\n",
    "os.makedirs(\"../data/embeddings\", exist_ok=True)\n",
    "embedder.save_embeddings(\n",
    "    emails_with_embeddings,\n",
    "    \"../data/embeddings/email_embeddings.json\"\n",
    ")\n",
    "\n",
    "print(f\"Embedded and saved {len(emails_with_embeddings)} emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the embeddings to understand their structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Examine the embeddings\n",
    "sample_email = emails_with_embeddings[0]\n",
    "\n",
    "print(f\"Email ID: {sample_email['id']}\")\n",
    "print(f\"Embedding shape: {np.array(sample_email['embedding']).shape}\")\n",
    "\n",
    "if 'chunk_embeddings' in sample_email:\n",
    "    print(f\"Number of chunks: {len(sample_email['chunks'])}\")\n",
    "    print(f\"Chunk embeddings shape: {np.array(sample_email['chunk_embeddings']).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up ChromaDB for Vector Storage\n",
    "\n",
    "Now, let's set up ChromaDB for efficient vector storage and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize ChromaDB store\n",
    "chroma_store = ChromaDBStore(\n",
    "    collection_name=\"email_embeddings\",\n",
    "    persist_directory=\"../data/embeddings/chroma_db\",\n",
    "    embedding_function=embedder.embedding_function\n",
    ")\n",
    "\n",
    "# Add emails to ChromaDB\n",
    "@time_function\n",
    "def add_emails_to_chroma(emails):\n",
    "    chroma_store.add_emails(emails)\n",
    "\n",
    "# Check if collection is empty before adding\n",
    "collection_stats = chroma_store.get_collection_stats()\n",
    "print(f\"Collection stats: {collection_stats}\")\n",
    "\n",
    "if collection_stats[\"count\"] == 0:\n",
    "    add_emails_to_chroma(processed_emails)\n",
    "    print(f\"Added {len(processed_emails)} emails to ChromaDB\")\n",
    "else:\n",
    "    print(f\"ChromaDB already contains {collection_stats['count']} emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implement Similarity Search\n",
    "\n",
    "Let's implement and test the similarity search functionality using both direct vector comparison and ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize retrievers\n",
    "vector_retriever = EmailRetriever(\n",
    "    embedder=embedder,\n",
    "    use_faiss=True,\n",
    "    index_path=\"../data/embeddings/faiss_index.bin\"\n",
    ")\n",
    "\n",
    "# Build the index\n",
    "@time_function\n",
    "def build_index(emails):\n",
    "    vector_retriever.build_index(emails)\n",
    "\n",
    "build_index(emails_with_embeddings)\n",
    "\n",
    "# Initialize ChromaDB retriever\n",
    "chroma_retriever = ChromaDBRetriever(chroma_store=chroma_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test the retrieval with some sample queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What's the status of the project?\",\n",
    "    \"When is the next team meeting?\",\n",
    "    \"Can you provide an update on the budget?\",\n",
    "    \"Is there any issue with the system?\",\n",
    "    \"What are the plans for the weekend?\"\n",
    "]\n",
    "\n",
    "# Test vector retrieval\n",
    "print(\"Vector Retrieval Results:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    \n",
    "    # Retrieve similar emails\n",
    "    start_time = time.time()\n",
    "    results = vector_retriever.retrieve(query, top_k=3)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Retrieved {len(results)} emails in {end_time - start_time:.4f} seconds\")\n",
    "    \n",
    "    # Display results\n",
    "    for i, result in enumerate(results):\n",
    "        metadata = result.get('metadata', {})\n",
    "        similarity = result.get('similarity_score', 0.0)\n",
    "        print(f\"Result {i+1}: {metadata.get('subject', '')} (Similarity: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test ChromaDB retrieval\n",
    "print(\"ChromaDB Retrieval Results:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    \n",
    "    # Retrieve similar emails\n",
    "    start_time = time.time()\n",
    "    results = chroma_retriever.retrieve(query, top_k=3)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Retrieved {len(results)} emails in {end_time - start_time:.4f} seconds\")\n",
    "    \n",
    "    # Display results\n",
    "    for i, result in enumerate(results):\n",
    "        metadata = result.get('metadata', {})\n",
    "        similarity = result.get('similarity_score', 0.0)\n",
    "        print(f\"Result {i+1}: {metadata.get('subject', '')} (Similarity: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implement Response Generation\n",
    "\n",
    "Now, let's implement the response generation using a pre-trained language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the generator\n",
    "generator = ResponseGenerator(model_name=\"google/flan-t5-base\")\n",
    "\n",
    "# Test response generation\n",
    "print(\"Response Generation:\")\n",
    "for query in test_queries[:2]:  # Use only the first two queries to save time\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    \n",
    "    # Retrieve similar emails\n",
    "    retrieved_emails = chroma_retriever.retrieve(query, top_k=3)\n",
    "    \n",
    "    # Generate response\n",
    "    start_time = time.time()\n",
    "    response = generator.generate_response(query, retrieved_emails)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Generated response in {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implement End-to-End RAG Pipeline\n",
    "\n",
    "Finally, let's implement the end-to-end RAG pipeline that combines retrieval and generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize the RAG pipeline\n",
    "rag_pipeline = RAGPipeline(\n",
    "    retriever=chroma_retriever,\n",
    "    generator=generator,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "# Test the RAG pipeline\n",
    "print(\"RAG Pipeline:\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    \n",
    "    # Process the query\n",
    "    start_time = time.time()\n",
    "    result = rag_pipeline.process_query(query)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(f\"Processed query in {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"Response: {result['response']}\")\n",
    "    print(f\"Retrieved {len(result['retrieved_emails'])} emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Models\n",
    "\n",
    "Let's save the models for later use in the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ChromaDB is already saved in the persist_directory\n",
    "print(f\"ChromaDB is saved in: {chroma_store.persist_directory}\")\n",
    "\n",
    "# FAISS index is already saved\n",
    "print(f\"FAISS index is saved in: {vector_retriever.index_path}\")\n",
    "\n",
    "# The transformer models are cached by the Hugging Face library\n",
    "print(f\"Embedding model: {embedder.model_name}\")\n",
    "print(f\"Generator model: {generator.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "In this notebook, we've:\n",
    "\n",
    "1. Loaded the preprocessed emails from the previous notebook\n",
    "2. Embedded the emails using a pre-trained Sentence Transformer model\n",
    "3. Set up ChromaDB for efficient vector storage and retrieval\n",
    "4. Implemented similarity search using both direct vector comparison and ChromaDB\n",
    "5. Implemented response generation using a pre-trained language model\n",
    "6. Created an end-to-end RAG pipeline that combines retrieval and generation\n",
    "7. Saved the models for later use in the API\n",
    "\n",
    "The RAG pipeline is now ready to be integrated into the API in the next steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}