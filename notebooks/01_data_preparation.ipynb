{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Wizard Assistant: Data Preparation\n",
    "\n",
    "This notebook demonstrates the data preparation process for the Email Wizard Assistant. We'll create a synthetic dataset of emails, preprocess them, and prepare them for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "# Import project modules\n",
    "from src.data.dataset import create_synthetic_dataset, load_dataset, split_dataset\n",
    "from src.data.preprocessing import preprocess_emails, save_preprocessed_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Synthetic Dataset\n",
    "\n",
    "We'll create a synthetic dataset of 60 emails with diverse topics, senders, and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories if they don't exist\n",
    "os.makedirs(\"../data/raw\", exist_ok=True)\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# Create synthetic dataset\n",
    "emails = create_synthetic_dataset(\n",
    "    num_emails=60,\n",
    "    output_path=\"../data/raw/synthetic_emails.json\",\n",
    "    preprocess=False  # We'll preprocess manually for demonstration\n",
    ")\n",
    "\n",
    "print(f\"Created {len(emails)} synthetic emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the Dataset\n",
    "\n",
    "Let's examine the synthetic emails to understand their structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier exploration\n",
    "emails_df = pd.DataFrame(emails)\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", emails_df.shape)\n",
    "print(\"\\nColumns:\")\n",
    "for col in emails_df.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Extract metadata into separate columns\n",
    "emails_df['subject'] = emails_df['metadata'].apply(lambda x: x.get('subject', ''))\n",
    "emails_df['sender'] = emails_df['metadata'].apply(lambda x: x.get('sender', ''))\n",
    "emails_df['recipient'] = emails_df['metadata'].apply(lambda x: x.get('recipient', ''))\n",
    "emails_df['topic'] = emails_df['metadata'].apply(lambda x: x.get('topic', ''))\n",
    "\n",
    "# Display topic distribution\n",
    "topic_counts = emails_df['topic'].value_counts()\n",
    "print(\"\\nTopic distribution:\")\n",
    "print(topic_counts)\n",
    "\n",
    "# Plot topic distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "topic_counts.plot(kind='bar')\n",
    "plt.title('Email Topic Distribution')\n",
    "plt.xlabel('Topic')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine a sample email to understand its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample email\n",
    "sample_email_idx = 0\n",
    "sample_email = emails[sample_email_idx]\n",
    "\n",
    "print(f\"Email ID: {sample_email['id']}\")\n",
    "print(f\"Metadata: {json.dumps(sample_email['metadata'], indent=2)}\")\n",
    "print(\"\\nContent:\")\n",
    "print(sample_email['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess the Emails\n",
    "\n",
    "Now, let's preprocess the emails to clean and normalize the text, extract metadata, and chunk long emails if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the emails\n",
    "processed_emails = preprocess_emails(emails)\n",
    "\n",
    "# Save the preprocessed emails\n",
    "save_preprocessed_emails(\n",
    "    processed_emails,\n",
    "    \"../data/processed/processed_emails.json\"\n",
    ")\n",
    "\n",
    "print(f\"Preprocessed and saved {len(processed_emails)} emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine a preprocessed email to see the changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample preprocessed email\n",
    "sample_processed_email = processed_emails[sample_email_idx]\n",
    "\n",
    "print(f\"Email ID: {sample_processed_email['id']}\")\n",
    "print(f\"Metadata: {json.dumps(sample_processed_email['metadata'], indent=2)}\")\n",
    "print(\"\\nRaw Text:\")\n",
    "print(sample_processed_email['raw_text'])\n",
    "print(\"\\nCleaned Text:\")\n",
    "print(sample_processed_email['cleaned_text'])\n",
    "print(\"\\nChunks:\")\n",
    "for i, chunk in enumerate(sample_processed_email['chunks']):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split the Dataset\n",
    "\n",
    "Let's split the dataset into training, validation, and test sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_emails, val_emails, test_emails = split_dataset(\n",
    "    processed_emails,\n",
    "    train_ratio=0.8,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.1,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(train_emails)} emails\")\n",
    "print(f\"Validation set: {len(val_emails)} emails\")\n",
    "print(f\"Test set: {len(test_emails)} emails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the Split Dataset\n",
    "\n",
    "Let's save the split dataset for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the split dataset\n",
    "os.makedirs(\"../data/processed/split\", exist_ok=True)\n",
    "\n",
    "# Save train set\n",
    "save_preprocessed_emails(\n",
    "    train_emails,\n",
    "    \"../data/processed/split/train_emails.json\"\n",
    ")\n",
    "\n",
    "# Save validation set\n",
    "save_preprocessed_emails(\n",
    "    val_emails,\n",
    "    \"../data/processed/split/val_emails.json\"\n",
    ")\n",
    "\n",
    "# Save test set\n",
    "save_preprocessed_emails(\n",
    "    test_emails,\n",
    "    \"../data/processed/split/test_emails.json\"\n",
    ")\n",
    "\n",
    "print(\"Saved split dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "In this notebook, we've:\n",
    "\n",
    "1. Created a synthetic dataset of 60 emails with diverse topics and content\n",
    "2. Explored the dataset to understand its structure and distribution\n",
    "3. Preprocessed the emails to clean and normalize the text\n",
    "4. Split the dataset into training, validation, and test sets\n",
    "5. Saved the processed and split dataset for later use\n",
    "\n",
    "The preprocessed emails are now ready for embedding and retrieval in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}