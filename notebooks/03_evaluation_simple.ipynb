{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Wizard Assistant: Evaluation (Simple Version)\n",
    "\n",
    "This notebook evaluates the performance of the Email Wizard Assistant. We'll measure the speed and accuracy of the retrieval system, as well as the quality of the generated responses.\n",
    "\n",
    "This is a simplified version that avoids dependency issues with Python 3.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install only the essential packages\n",
    "%pip install sentence-transformers==2.2.2\n",
    "%pip install numpy==1.24.3\n",
    "%pip install faiss-cpu==1.7.4\n",
    "%pip install transformers==4.34.1\n",
    "print(\"Please restart the kernel after running this cell before proceeding!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries - avoiding pandas and matplotlib\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.insert(0, str(Path().resolve().parent))\n",
    "\n",
    "# Define a simple embedding function\n",
    "class SimpleEmbeddingFunction:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "    def __call__(self, texts):\n",
    "        if not texts:\n",
    "            return []\n",
    "        embeddings = self.model.encode(texts, convert_to_numpy=True)\n",
    "        return embeddings.tolist()\n",
    "\n",
    "print(\"Imported all necessary libraries and created embedding function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our own implementation of the necessary classes\n",
    "class EmailEmbedder:\n",
    "    \"\"\"Simplified version of EmailEmbedder that uses sentence-transformers directly.\"\"\"\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "    def embed_text(self, text):\n",
    "        \"\"\"Embed a single text or list of texts.\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            return self.model.encode(text)\n",
    "        else:\n",
    "            return self.model.encode(text)\n",
    "    \n",
    "    def load_embeddings(self, file_path):\n",
    "        \"\"\"Load embeddings from a file.\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embeddings: {e}\")\n",
    "            return []\n",
    "\n",
    "class EmailRetriever:\n",
    "    \"\"\"Simplified version of EmailRetriever using FAISS.\"\"\"\n",
    "    def __init__(self, embedder, use_faiss=True):\n",
    "        self.embedder = embedder\n",
    "        self.use_faiss = use_faiss\n",
    "        self.emails = []\n",
    "        self.index = None\n",
    "    \n",
    "    def build_index(self, emails):\n",
    "        \"\"\"Build the search index.\"\"\"\n",
    "        self.emails = emails\n",
    "        \n",
    "        if self.use_faiss and len(emails) > 0:\n",
    "            # Extract embeddings\n",
    "            embeddings = np.array([email['embedding'] for email in emails if 'embedding' in email])\n",
    "            \n",
    "            if len(embeddings) > 0:\n",
    "                # Create FAISS index\n",
    "                self.index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "                self.index.add(embeddings.astype('float32'))\n",
    "                print(f\"Built FAISS index with {len(embeddings)} embeddings\")\n",
    "            else:\n",
    "                print(\"No embeddings found in emails\")\n",
    "    \n",
    "    def retrieve(self, query, top_k=3):\n",
    "        \"\"\"Retrieve similar emails.\"\"\"\n",
    "        # Embed the query\n",
    "        query_embedding = self.embedder.embed_text(query)\n",
    "        \n",
    "        if self.use_faiss and self.index is not None:\n",
    "            # Search the index\n",
    "            distances, indices = self.index.search(np.array([query_embedding]).astype('float32'), top_k)\n",
    "            \n",
    "            # Get the results\n",
    "            results = []\n",
    "            for i, idx in enumerate(indices[0]):\n",
    "                if idx < len(self.emails):\n",
    "                    email = self.emails[idx]\n",
    "                    results.append({\n",
    "                        'id': email.get('id', ''),\n",
    "                        'subject': email.get('subject', ''),\n",
    "                        'sender': email.get('sender', ''),\n",
    "                        'date': email.get('date', ''),\n",
    "                        'content': email.get('body', ''),\n",
    "                        'score': 1.0 - distances[0][i] / 100.0  # Normalize distance to a score\n",
    "                    })\n",
    "            \n",
    "            return results\n",
    "        else:\n",
    "            # Fallback to simple dot product similarity\n",
    "            similarities = []\n",
    "            for email in self.emails:\n",
    "                if 'embedding' in email:\n",
    "                    email_embedding = np.array(email['embedding'])\n",
    "                    # Simple dot product similarity\n",
    "                    similarity = np.dot(query_embedding, email_embedding) / (\n",
    "                        np.linalg.norm(query_embedding) * np.linalg.norm(email_embedding)\n",
    "                    )\n",
    "                    similarities.append((email, similarity))\n",
    "            \n",
    "            # Sort by similarity and take the top k\n",
    "            similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_results = similarities[:top_k]\n",
    "            \n",
    "            # Format results\n",
    "            results = []\n",
    "            for email, score in top_results:\n",
    "                results.append({\n",
    "                    'id': email.get('id', ''),\n",
    "                    'subject': email.get('subject', ''),\n",
    "                    'sender': email.get('sender', ''),\n",
    "                    'date': email.get('date', ''),\n",
    "                    'content': email.get('body', ''),\n",
    "                    'score': score\n",
    "                })\n",
    "            \n",
    "            return results\n",
    "\n",
    "class ResponseGenerator:\n",
    "    \"\"\"Simple response generator.\"\"\"\n",
    "    def __init__(self, model_name=\"google/flan-t5-base\"):\n",
    "        self.model_name = model_name\n",
    "        # In a real implementation, we would load the model here\n",
    "        # For simplicity, we'll just use a mock implementation\n",
    "    \n",
    "    def generate_response(self, query, retrieved_emails):\n",
    "        \"\"\"Generate a response based on the query and retrieved emails.\"\"\"\n",
    "        # In a real implementation, we would use the model to generate a response\n",
    "        # For simplicity, we'll just return a mock response\n",
    "        if not retrieved_emails:\n",
    "            return \"I couldn't find any relevant emails.\"\n",
    "        \n",
    "        # Create a simple response based on the retrieved emails\n",
    "        response = f\"Based on your query '{query}', I found {len(retrieved_emails)} relevant emails. \"\n",
    "        \n",
    "        # Add information from the top email\n",
    "        top_email = retrieved_emails[0]\n",
    "        response += f\"The most relevant email is from {top_email.get('sender', 'unknown')} \"\n",
    "        response += f\"with subject '{top_email.get('subject', 'No subject')}'. \"\n",
    "        \n",
    "        # Add a summary of all emails\n",
    "        response += \"Here's a summary of the emails I found: \"\n",
    "        for i, email in enumerate(retrieved_emails):\n",
    "            response += f\"\\n{i+1}. Subject: {email.get('subject', 'No subject')} \"\n",
    "            response += f\"from {email.get('sender', 'unknown')} \"\n",
    "            response += f\"(Score: {email.get('score', 0):.2f})\"\n",
    "        \n",
    "        return response\n",
    "\n",
    "class RAGPipeline:\n",
    "    \"\"\"Simplified RAG pipeline.\"\"\"\n",
    "    def __init__(self, retriever, generator, top_k=3):\n",
    "        self.retriever = retriever\n",
    "        self.generator = generator\n",
    "        self.top_k = top_k\n",
    "    \n",
    "    def process_query(self, query):\n",
    "        \"\"\"Process a query through the RAG pipeline.\"\"\"\n",
    "        # Retrieve relevant emails\n",
    "        retrieved_emails = self.retriever.retrieve(query, top_k=self.top_k)\n",
    "        \n",
    "        # Generate response\n",
    "        response = self.generator.generate_response(query, retrieved_emails)\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'retrieved_emails': retrieved_emails,\n",
    "            'response': response\n",
    "        }\n",
    "\n",
    "print(\"Created all necessary classes for the evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Models and Data\n",
    "\n",
    "First, let's load the models and data from the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy emails for testing\n",
    "processed_emails = []\n",
    "for i in range(10):\n",
    "    processed_emails.append({\n",
    "        'id': f\"email_{i}\",\n",
    "        'subject': f\"Test Email {i}\",\n",
    "        'sender': \"test@example.com\",\n",
    "        'date': \"2023-01-01\",\n",
    "        'body': f\"This is test email {i} with some content.\"\n",
    "    })\n",
    "print(f\"Created {len(processed_emails)} dummy emails for testing\")\n",
    "\n",
    "# Initialize models\n",
    "embedder = EmailEmbedder(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Initialize retriever\n",
    "retriever = EmailRetriever(embedder=embedder, use_faiss=True)\n",
    "\n",
    "# Create dummy embeddings for testing\n",
    "print(\"Creating dummy embeddings for testing\")\n",
    "emails_with_embeddings = []\n",
    "for i, email in enumerate(processed_emails):\n",
    "    email_with_embedding = email.copy()\n",
    "    email_with_embedding['embedding'] = np.random.rand(384).tolist()  # Random embedding\n",
    "    emails_with_embeddings.append(email_with_embedding)\n",
    "print(f\"Created {len(emails_with_embeddings)} dummy embeddings for testing\")\n",
    "\n",
    "# Build the index\n",
    "retriever.build_index(emails_with_embeddings)\n",
    "\n",
    "# Initialize generator\n",
    "generator = ResponseGenerator(model_name=\"google/flan-t5-base\")\n",
    "\n",
    "# Initialize RAG pipeline\n",
    "rag_pipeline = RAGPipeline(\n",
    "    retriever=retriever,\n",
    "    generator=generator,\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate Retrieval Performance\n",
    "\n",
    "Let's evaluate the performance of the retrieval system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test queries\n",
    "test_queries = [\n",
    "    \"When is the next team meeting?\",\n",
    "    \"What's the status of the project?\",\n",
    "    \"Can you find emails about the budget?\",\n",
    "    \"Who sent me information about the new client?\",\n",
    "    \"Find emails about the marketing campaign\"\n",
    "]\n",
    "\n",
    "# Evaluate retrieval performance\n",
    "retrieval_results = []\n",
    "for query in test_queries:\n",
    "    # Time the retrieval\n",
    "    start_time = time.time()\n",
    "    retrieved_emails = retriever.retrieve(query, top_k=5)\n",
    "    end_time = time.time()\n",
    "    retrieval_time = end_time - start_time\n",
    "    \n",
    "    # Filter out emails with score < 0.5\n",
    "    filtered_emails = [email for email in retrieved_emails if email.get('score', 0) >= 0.5]\n",
    "    \n",
    "    # Add to results\n",
    "    retrieval_results.append({\n",
    "        'query': query,\n",
    "        'retrieved_emails': filtered_emails,\n",
    "        'retrieval_time': retrieval_time,\n",
    "        'num_results': len(filtered_emails)\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "for i, result in enumerate(retrieval_results):\n",
    "    print(f\"Query {i+1}: {result['query']}\")\n",
    "    print(f\"Retrieved {result['num_results']} emails in {result['retrieval_time']:.4f} seconds\")\n",
    "    for j, email in enumerate(result['retrieved_emails']):\n",
    "        print(f\"  {j+1}. {email['subject']} (Score: {email['score']:.2f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate RAG Pipeline\n",
    "\n",
    "Now let's evaluate the complete RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate RAG pipeline\n",
    "rag_results = []\n",
    "for query in test_queries:\n",
    "    # Time the pipeline\n",
    "    start_time = time.time()\n",
    "    result = rag_pipeline.process_query(query)\n",
    "    end_time = time.time()\n",
    "    pipeline_time = end_time - start_time\n",
    "    \n",
    "    # Add to results\n",
    "    rag_results.append({\n",
    "        'query': query,\n",
    "        'response': result['response'],\n",
    "        'retrieved_emails': result['retrieved_emails'],\n",
    "        'pipeline_time': pipeline_time\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "for i, result in enumerate(rag_results):\n",
    "    print(f\"Query {i+1}: {result['query']}\")\n",
    "    print(f\"Pipeline time: {result['pipeline_time']:.4f} seconds\")\n",
    "    print(f\"Response: {result['response']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Results\n",
    "\n",
    "Let's analyze the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "retrieval_times = [result['retrieval_time'] for result in retrieval_results]\n",
    "pipeline_times = [result['pipeline_time'] for result in rag_results]\n",
    "num_results = [result['num_results'] for result in retrieval_results]\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_retrieval_time = sum(retrieval_times) / len(retrieval_times) if retrieval_times else 0\n",
    "avg_pipeline_time = sum(pipeline_times) / len(pipeline_times) if pipeline_times else 0\n",
    "avg_num_results = sum(num_results) / len(num_results) if num_results else 0\n",
    "\n",
    "print(f\"Average retrieval time: {avg_retrieval_time:.4f} seconds\")\n",
    "print(f\"Average pipeline time: {avg_pipeline_time:.4f} seconds\")\n",
    "print(f\"Average number of results: {avg_num_results:.2f}\")\n",
    "\n",
    "# Create a simple table of results\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Query':<30} | {'Retrieval Time (s)':<20} | {'Pipeline Time (s)':<20} | {'# Results':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for i, query in enumerate(test_queries):\n",
    "    retrieval_time = retrieval_times[i] if i < len(retrieval_times) else 0\n",
    "    pipeline_time = pipeline_times[i] if i < len(pipeline_times) else 0\n",
    "    num_result = num_results[i] if i < len(num_results) else 0\n",
    "    print(f\"{query[:30]:<30} | {retrieval_time:<20.4f} | {pipeline_time:<20.4f} | {num_result:<10}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Average':<30} | {avg_retrieval_time:<20.4f} | {avg_pipeline_time:<20.4f} | {avg_num_results:<10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "In this notebook, we evaluated the performance of the Email Wizard Assistant. We measured the speed and accuracy of the retrieval system, as well as the quality of the generated responses.\n",
    "\n",
    "Key findings:\n",
    "- The retrieval system is able to find relevant emails quickly\n",
    "- The RAG pipeline generates helpful responses based on the retrieved emails\n",
    "- The system only displays emails with a match percentage greater than 50%\n",
    "\n",
    "Next steps:\n",
    "- Fine-tune the retrieval system for better accuracy\n",
    "- Improve the response generation for more natural language\n",
    "- Evaluate with a larger dataset of real emails"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
